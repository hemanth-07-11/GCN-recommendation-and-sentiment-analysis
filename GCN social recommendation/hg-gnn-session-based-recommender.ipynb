{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## GCN : Session embedding based recommender ","metadata":{}},{"cell_type":"code","source":"!pip install -qq dgl-cu110 dglgo -f https://data.dgl.ai/wheels/repo.html &>/dev/null","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:39:30.022187Z","iopub.execute_input":"2023-04-12T06:39:30.022929Z","iopub.status.idle":"2023-04-12T06:40:15.183900Z","shell.execute_reply.started":"2023-04-12T06:39:30.022836Z","shell.execute_reply":"2023-04-12T06:40:15.182559Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cudf\nfrom pandas import Timedelta\nimport os\nfrom tqdm.notebook import tqdm\nimport pickle\nfrom torch.utils.data import Dataset, DataLoader\nimport math\nfrom operator import itemgetter\nimport dgl\npd.set_option('display.max_rows', 10000)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:15.186659Z","iopub.execute_input":"2023-04-12T06:40:15.187069Z","iopub.status.idle":"2023-04-12T06:40:19.573097Z","shell.execute_reply.started":"2023-04-12T06:40:15.187027Z","shell.execute_reply":"2023-04-12T06:40:19.571869Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"DGL backend not selected or invalid.  Assuming PyTorch for now.\n","output_type":"stream"},{"name":"stdout","text":"Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","output_type":"stream"}]},{"cell_type":"code","source":"last_fm_union = cudf.read_parquet('/kaggle/input/lastfm-dataset/lastfm_union.parquet')\nlen(last_fm_union)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:19.589165Z","iopub.execute_input":"2023-04-12T06:40:19.595577Z","iopub.status.idle":"2023-04-12T06:40:33.884458Z","shell.execute_reply.started":"2023-04-12T06:40:19.595527Z","shell.execute_reply":"2023-04-12T06:40:33.883515Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"19098852"},"metadata":{}}]},{"cell_type":"code","source":"last_fm_union.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:33.887215Z","iopub.execute_input":"2023-04-12T06:40:33.887926Z","iopub.status.idle":"2023-04-12T06:40:33.996441Z","shell.execute_reply.started":"2023-04-12T06:40:33.887886Z","shell.execute_reply":"2023-04-12T06:40:33.995402Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       user_id           timestamp                             artist_id  \\\n0  user_000001 2009-05-04 23:08:57  f1b1cf71-bd35-4e99-8624-24a6e15f133a   \n1  user_000001 2009-05-04 13:54:10  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n2  user_000001 2009-05-04 13:52:04  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n\n    artist_name track_id                                  track_name gender  \\\n0     Deep Dish     <NA>  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007      M   \n1  åæ¬é¾ä¸     <NA>           Composition 0919 (Live_2009_4_15)      M   \n2  åæ¬é¾ä¸     <NA>                        Mc2 (Live_2009_4_15)      M   \n\n    age country registered  \n0  <NA>   JAPAN 2006-08-13  \n1  <NA>   JAPAN 2006-08-13  \n2  <NA>   JAPAN 2006-08-13  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>timestamp</th>\n      <th>artist_id</th>\n      <th>artist_name</th>\n      <th>track_id</th>\n      <th>track_name</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>country</th>\n      <th>registered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_000001</td>\n      <td>2009-05-04 23:08:57</td>\n      <td>f1b1cf71-bd35-4e99-8624-24a6e15f133a</td>\n      <td>Deep Dish</td>\n      <td>&lt;NA&gt;</td>\n      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n      <td>M</td>\n      <td>&lt;NA&gt;</td>\n      <td>JAPAN</td>\n      <td>2006-08-13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_000001</td>\n      <td>2009-05-04 13:54:10</td>\n      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n      <td>åæ¬é¾ä¸</td>\n      <td>&lt;NA&gt;</td>\n      <td>Composition 0919 (Live_2009_4_15)</td>\n      <td>M</td>\n      <td>&lt;NA&gt;</td>\n      <td>JAPAN</td>\n      <td>2006-08-13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_000001</td>\n      <td>2009-05-04 13:52:04</td>\n      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n      <td>åæ¬é¾ä¸</td>\n      <td>&lt;NA&gt;</td>\n      <td>Mc2 (Live_2009_4_15)</td>\n      <td>M</td>\n      <td>&lt;NA&gt;</td>\n      <td>JAPAN</td>\n      <td>2006-08-13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(f\" # Unique User : {last_fm_union['user_id'].nunique()}, # Unique Artist : {last_fm_union['artist_id'].nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:33.997963Z","iopub.execute_input":"2023-04-12T06:40:33.998408Z","iopub.status.idle":"2023-04-12T06:40:35.708515Z","shell.execute_reply.started":"2023-04-12T06:40:33.998371Z","shell.execute_reply":"2023-04-12T06:40:35.707390Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":" # Unique User : 992, # Unique Artist : 107295\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_session_id(df, interval):\n    df_prev = df.shift()\n    is_new_session = (df.userId != df_prev.userId) | (\n        df.timestamp - df_prev.timestamp > interval\n    )\n    session_id = is_new_session.cumsum() - 1\n    return session_id\n\n\ndef group_sessions(df, interval):\n    sessionId = get_session_id(df, interval)\n    df = df.assign(sessionId=sessionId)\n    return df\n\n\ndef filter_short_sessions(df, min_len=2):\n    session_len = df.groupby('sessionId', sort=False).size()\n    long_sessions = session_len[session_len >= min_len].index\n    df_long = df[df.sessionId.isin(long_sessions)]\n    return df_long\n\n\ndef filter_infreq_items(df, min_support=5):\n    item_support = df.groupby('itemId', sort=False).size()\n    freq_items = item_support[item_support >= min_support].index\n    df_freq = df[df.itemId.isin(freq_items)]\n    return df_freq\n\n\ndef filter_until_all_long_and_freq(df, min_len=2, min_support=5):\n    while True:\n        df_long = filter_short_sessions(df, min_len)\n        df_freq = filter_infreq_items(df_long, min_support)\n        if len(df_freq) == len(df):\n            break\n        df = df_freq\n    return df\n\n\ndef truncate_long_sessions(df, max_len=20, is_sorted=False):\n    if not is_sorted:\n        df = df.sort_values(['sessionId', 'timestamp'])\n    itemIdx = df.groupby('sessionId').cumcount()\n    df_t = df[itemIdx < max_len]\n    return df_t\n\n\ndef update_id(df, field):\n    labels = cudf.factorize(df[field])[0]\n    kwargs = {field: labels}\n    df = df.assign(**kwargs)\n    return df\n\n\ndef remove_immediate_repeats(df):\n    df_prev = df.shift()\n    is_not_repeat = (df.sessionId != df_prev.sessionId) | (df.itemId != df_prev.itemId)\n    df_no_repeat = df[is_not_repeat]\n    return df_no_repeat\n\n\ndef reorder_sessions_by_endtime(df):\n    endtime = df.groupby('sessionId', sort=False).timestamp.max()\n    df_endtime = endtime.sort_values().reset_index()\n    oid2nid = dict(zip(df_endtime.sessionId, df_endtime.index))\n    sessionId_new = df.sessionId.map(oid2nid)\n    df = df.assign(sessionId=sessionId_new)\n    df = df.sort_values(['sessionId', 'timestamp'])\n    return df\n\n\ndef keep_top_n_items(df, n):\n    item_support = df.groupby('itemId', sort=False).size()\n    top_items = item_support.nlargest(n).index\n    df_top = df[df.itemId.isin(top_items)]\n    return df_top\n\n\ndef split_by_time(df, timedelta):\n    max_time = df.timestamp.max()\n    end_time = df.groupby('sessionId').timestamp.max()\n    split_time = max_time - timedelta\n    train_sids = end_time[end_time < split_time].index\n    df_train = df[df.sessionId.isin(train_sids)]\n    df_test = df[~df.sessionId.isin(train_sids)]\n    return df_train, df_test\n\n\ndef train_test_split(df, test_split=0.2):\n    endtime = df.groupby('sessionId', sort=False).timestamp.max()\n    endtime = endtime.sort_values()\n    num_tests = int(len(endtime) * test_split)\n    test_session_ids = endtime.index[-num_tests:]\n    df_train = df[~df.sessionId.isin(test_session_ids)]\n    df_test = df[df.sessionId.isin(test_session_ids)]\n    return df_train, df_test\n\n\ndef save_sessions(df, filepath):\n    df = reorder_sessions_by_endtime(df)\n    sessions = df.groupby('sessionId').itemId.apply(lambda x: ','.join(map(str, x)))\n    sessions.to_csv(filepath, sep='\\t', header=False, index=False)\n\n\ndef save_dataset(dataset_dir, df_train, df_test):\n\n    df_test = df_test[df_test.itemId.isin(df_train.itemId.unique())]\n    df_test = filter_short_sessions(df_test)\n\n    print(f'No. of Clicks: {len(df_train) + len(df_test)}')\n    print(f'No. of Items: {df_train.itemId.nunique()}')\n\n    train_itemId_new, uniques = pd.factorize(df_train.itemId)\n    df_train = df_train.assign(itemId=train_itemId_new)\n    oid2nid = {oid: i for i, oid in enumerate(uniques)}\n    test_itemId_new = df_test.itemId.map(oid2nid)\n    df_test = df_test.assign(itemId=test_itemId_new)\n\n    print(f'saving dataset to {dataset_dir}')\n    dataset_dir.mkdir(parents=True, exist_ok=True)\n    save_sessions(df_train, dataset_dir / 'train.txt')\n    save_sessions(df_test, dataset_dir / 'test.txt')\n    num_items = len(uniques)\n    with open(dataset_dir / 'num_items.txt', 'w') as f:\n        f.write(str(num_items))","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:35.710242Z","iopub.execute_input":"2023-04-12T06:40:35.710624Z","iopub.status.idle":"2023-04-12T06:40:35.733661Z","shell.execute_reply.started":"2023-04-12T06:40:35.710587Z","shell.execute_reply":"2023-04-12T06:40:35.732605Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"interval = Timedelta(hours=8)\nn = 40000\n\nlast_fm_union = cudf.read_parquet('/kaggle/input/lastfm-dataset/lastfm_union.parquet')\nlast_fm_union = last_fm_union[['user_id','timestamp','artist_id']]\nlast_fm_union.columns = ['userId', 'timestamp', 'itemId']\n\nlast_fm_union = last_fm_union.dropna()\nlast_fm_union = update_id(last_fm_union, 'userId')\nlast_fm_union = update_id(last_fm_union, 'itemId')\nlast_fm_union = last_fm_union.sort_values(['userId', 'timestamp'])\n\nlast_fm_union = group_sessions(last_fm_union, interval)\nlast_fm_union = remove_immediate_repeats(last_fm_union)\nlast_fm_union = truncate_long_sessions(last_fm_union, is_sorted=True)\nlast_fm_union = keep_top_n_items(last_fm_union, n)\nlast_fm_union = filter_until_all_long_and_freq(last_fm_union)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:35.735082Z","iopub.execute_input":"2023-04-12T06:40:35.735507Z","iopub.status.idle":"2023-04-12T06:40:40.894536Z","shell.execute_reply.started":"2023-04-12T06:40:35.735455Z","shell.execute_reply":"2023-04-12T06:40:40.893526Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"last_fm_union.tail(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:40.896181Z","iopub.execute_input":"2023-04-12T06:40:40.896623Z","iopub.status.idle":"2023-04-12T06:40:40.924522Z","shell.execute_reply.started":"2023-04-12T06:40:40.896583Z","shell.execute_reply":"2023-04-12T06:40:40.923438Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"          userId           timestamp  itemId  sessionId\n19080499     991 2009-05-02 19:51:15   15252     385133\n19080498     991 2009-05-02 19:57:17    8519     385133\n19080497     991 2009-05-03 03:48:04   59521     385133\n19080485     991 2009-05-03 20:28:10   97231     385134\n19080484     991 2009-05-04 00:27:31  105799     385134","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>timestamp</th>\n      <th>itemId</th>\n      <th>sessionId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19080499</th>\n      <td>991</td>\n      <td>2009-05-02 19:51:15</td>\n      <td>15252</td>\n      <td>385133</td>\n    </tr>\n    <tr>\n      <th>19080498</th>\n      <td>991</td>\n      <td>2009-05-02 19:57:17</td>\n      <td>8519</td>\n      <td>385133</td>\n    </tr>\n    <tr>\n      <th>19080497</th>\n      <td>991</td>\n      <td>2009-05-03 03:48:04</td>\n      <td>59521</td>\n      <td>385133</td>\n    </tr>\n    <tr>\n      <th>19080485</th>\n      <td>991</td>\n      <td>2009-05-03 20:28:10</td>\n      <td>97231</td>\n      <td>385134</td>\n    </tr>\n    <tr>\n      <th>19080484</th>\n      <td>991</td>\n      <td>2009-05-04 00:27:31</td>\n      <td>105799</td>\n      <td>385134</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"After Pre-processing - \")\nprint(f\"#Users : {last_fm_union['userId'].nunique()} #Items : {last_fm_union['itemId'].nunique()} #Sessions : {last_fm_union['sessionId'].nunique()} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:40.926239Z","iopub.execute_input":"2023-04-12T06:40:40.927341Z","iopub.status.idle":"2023-04-12T06:40:40.947945Z","shell.execute_reply.started":"2023-04-12T06:40:40.927294Z","shell.execute_reply":"2023-04-12T06:40:40.946951Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"After Pre-processing - \n#Users : 989 #Items : 39767 #Sessions : 325957 \n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir lastfm","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:40.952578Z","iopub.execute_input":"2023-04-12T06:40:40.952834Z","iopub.status.idle":"2023-04-12T06:40:41.930239Z","shell.execute_reply.started":"2023-04-12T06:40:40.952811Z","shell.execute_reply":"2023-04-12T06:40:41.928923Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"saved_path = 'lastfm'","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:41.931939Z","iopub.execute_input":"2023-04-12T06:40:41.933062Z","iopub.status.idle":"2023-04-12T06:40:41.938582Z","shell.execute_reply.started":"2023-04-12T06:40:41.933018Z","shell.execute_reply":"2023-04-12T06:40:41.937434Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"last_fm_union.to_csv(f'{saved_path}/'+'data.txt',sep=',',header=None,index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:41.940077Z","iopub.execute_input":"2023-04-12T06:40:41.941157Z","iopub.status.idle":"2023-04-12T06:40:42.320572Z","shell.execute_reply.started":"2023-04-12T06:40:41.941121Z","shell.execute_reply":"2023-04-12T06:40:42.319437Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def _agg_all_seq(df):\n\n    res=[]\n    for u,ug in tqdm(df.groupby('userId')):\n        res+=ug.groupby('sessionId')['itemId'].agg(list).to_arrow().to_pylist()\n    with open(os.path.join(saved_path,'all_train_seq.txt'),'wb') as f:\n        pickle.dump(res,f)\n    return res","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:42.321934Z","iopub.execute_input":"2023-04-12T06:40:42.323002Z","iopub.status.idle":"2023-04-12T06:40:42.330881Z","shell.execute_reply.started":"2023-04-12T06:40:42.322962Z","shell.execute_reply":"2023-04-12T06:40:42.329845Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def _agg_df(df):\n    res={}\n    for u,ug in tqdm(df.groupby('userId')):\n        res.setdefault(u,[])\n        res[u]=ug.groupby('sessionId')['itemId'].agg(list).to_arrow().to_pylist()\n    return res","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:42.332530Z","iopub.execute_input":"2023-04-12T06:40:42.333165Z","iopub.status.idle":"2023-04-12T06:40:42.342740Z","shell.execute_reply.started":"2023-04-12T06:40:42.333128Z","shell.execute_reply":"2023-04-12T06:40:42.341752Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def _split_data():\n    print('split data...')\n    #splitter = self.conf['dataset.split']\n    val_ratio = 0.2\n    test_split= 0.2\n    df=cudf.read_csv(os.path.join(saved_path,'data.txt'),header=None,names=['userId', 'timestamp', 'itemId','sessionId'])\n    print(df['userId'].nunique())\n    print(df['itemId'].nunique())\n    print(df['itemId'].max(),df['itemId'].min())\n    endtime = df.groupby('sessionId', sort=False).timestamp.max()\n    endtime = endtime.sort_values()\n    num_tests = int(len(endtime) * test_split)\n    test_session_ids = endtime.index[-num_tests:]\n    df_train = df[~df.sessionId.isin(test_session_ids)]\n    df_test = df[df.sessionId.isin(test_session_ids)].reset_index(drop=True)\n\n    df_test = df_test[df_test.itemId.isin(df_train.itemId.unique())]\n    df_test = filter_short_sessions(df_test)\n\n    train_itemId_new, uniques = cudf.factorize(df_train.itemId)\n    df_train = df_train.assign(itemId=train_itemId_new)\n    oid2nid = {oid: i for i, oid in enumerate(uniques.to_pandas())}\n    test_itemId_new = df_test.itemId.map(oid2nid)\n    df_test = df_test.assign(itemId=test_itemId_new)\n    df_train['userId']+=1\n    df_train['itemId']+=1\n    df_test['userId']+=1\n    df_test['itemId']+=1\n\n    _agg_all_seq(df_train)\n\n\n    print(df_train['userId'].min(),df_train['userId'].max())\n    print(df_train['itemId'].max(),df_train['itemId'].min())\n    print(df_test['itemId'].max(),df_test['itemId'].min())\n\n    df_test=df_test.reset_index(drop=True)\n    df_val= df_test.sample(frac=val_ratio)\n    part_test=df_test[~df_test.index.isin(df_val.index)]\n    \n    df_train.to_csv(os.path.join(saved_path, 'df_train.csv'), header = True, index = False)\n    df_val.to_csv(os.path.join(saved_path, 'df_val.csv'), header = True, index = False)\n    part_test.to_csv(os.path.join(saved_path, 'part_test.csv'), header = True, index = False)\n    df_test.to_csv(os.path.join(saved_path, 'df_test.csv'), header = True, index = False)\n        \n    with open(os.path.join(saved_path,'train.pkl'),'wb') as f:\n        pickle.dump(_agg_df(df_train),f)\n        \n    with open(os.path.join(saved_path,'val.pkl'),'wb') as f:\n        pickle.dump(_agg_df(df_val),f)\n\n    with open(os.path.join(saved_path,'test.pkl'),'wb') as f:\n        pickle.dump(_agg_df(part_test),f)\n        \n    with open(os.path.join(saved_path,'all_test.pkl'),'wb') as f:\n        pickle.dump(_agg_df(df_test),f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:42.346412Z","iopub.execute_input":"2023-04-12T06:40:42.346758Z","iopub.status.idle":"2023-04-12T06:40:42.363335Z","shell.execute_reply.started":"2023-04-12T06:40:42.346732Z","shell.execute_reply":"2023-04-12T06:40:42.362194Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%%time\n_split_data()","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:40:42.366793Z","iopub.execute_input":"2023-04-12T06:40:42.367153Z","iopub.status.idle":"2023-04-12T06:41:19.311294Z","shell.execute_reply.started":"2023-04-12T06:40:42.367112Z","shell.execute_reply":"2023-04-12T06:41:19.310261Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"split data...\n989\n39767\n107291 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9d60b93c724b09946173e721f8bc05"}},"metadata":{}},{"name":"stdout","text":"1 992\n38569 1\n38569 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235cada283554249b31ac48d68336698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e861912491b54a90aa94cf6cdab69125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b55c5e075e4be898f3edaad1ff0a16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45629fb4305c4878b65d034ccd0a446a"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 35.9 s, sys: 958 ms, total: 36.8 s\nWall time: 36.9 s\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/working/lastfm/train.pkl', 'rb') as f:\n    train_pkl = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:19.312736Z","iopub.execute_input":"2023-04-12T06:41:19.313384Z","iopub.status.idle":"2023-04-12T06:41:19.920729Z","shell.execute_reply.started":"2023-04-12T06:41:19.313344Z","shell.execute_reply":"2023-04-12T06:41:19.919502Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(f\" Number of Unique Users in Output Dictionary : {len(train_pkl) }\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:19.922533Z","iopub.execute_input":"2023-04-12T06:41:19.923112Z","iopub.status.idle":"2023-04-12T06:41:19.928655Z","shell.execute_reply.started":"2023-04-12T06:41:19.923071Z","shell.execute_reply":"2023-04-12T06:41:19.927540Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":" Number of Unique Users in Output Dictionary : 897\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\" Number of sessions for Used ID 1 is {len(train_pkl[1])} and 1st Session of User 1 has {len(train_pkl[1][0])} items while 2nd session has {len(train_pkl[1][1])} items\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:19.930396Z","iopub.execute_input":"2023-04-12T06:41:19.931049Z","iopub.status.idle":"2023-04-12T06:41:19.939141Z","shell.execute_reply.started":"2023-04-12T06:41:19.931012Z","shell.execute_reply":"2023-04-12T06:41:19.938077Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":" Number of sessions for Used ID 1 is 284 and 1st Session of User 1 has 17 items while 2nd session has 16 items\n","output_type":"stream"}]},{"cell_type":"code","source":"def common_seq(data_list):\n    out_seqs=[]\n    label=[]\n    uid=[]\n    for u in tqdm(data_list,desc='gen_seq...',leave=False):\n        u_seqs=data_list[u]\n        for seq in u_seqs:      \n            for i in range(1,len(seq)):\n                uid.append(int(u))\n                out_seqs.append(seq[:-i])\n                label.append([seq[-i]])\n    \n    final_seqs=[]\n    for i in range(len(uid)):\n        final_seqs.append([uid[i],out_seqs[i],label[i]])\n    return final_seqs","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:19.940742Z","iopub.execute_input":"2023-04-12T06:41:19.941353Z","iopub.status.idle":"2023-04-12T06:41:19.949450Z","shell.execute_reply.started":"2023-04-12T06:41:19.941316Z","shell.execute_reply":"2023-04-12T06:41:19.948536Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(saved_path,'train.pkl'),'rb') as f:\n     train_data=pickle.load(f)\n        \nmax_vid=0\nmax_uid=0\n\nfor u in tqdm(train_data):\n    if u>max_uid:\n        max_uid=u\n    for sess in train_data[u]:\n        if max_vid<max(sess):\n            max_vid=max(sess)\n        \ntry:\n    with open(os.path.join(saved_path,'all_test.pkl'),'rb') as f:\n        test_data=pickle.load(f)\nexcept:\n    with open(os.path.join(saved_path,'test.pkl'),'rb') as f:\n        test_data=pickle.load(f)\n        \ntrain_data=common_seq(train_data)\ntest_data=common_seq(test_data)\n\nwith open(os.path.join(saved_path,'test_seq.pkl'),'wb') as f:\n    pickle.dump(test_data,f)\n\nwith open(os.path.join(saved_path,'train_seq.pkl'),'wb') as f:\n    pickle.dump(train_data,f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:19.950996Z","iopub.execute_input":"2023-04-12T06:41:19.951512Z","iopub.status.idle":"2023-04-12T06:41:37.447254Z","shell.execute_reply.started":"2023-04-12T06:41:19.951458Z","shell.execute_reply":"2023-04-12T06:41:37.446228Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e96db3f121540d680f0e81c20350591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"gen_seq...:   0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"gen_seq...:   0%|          | 0/796 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"with open('/kaggle/working/lastfm/train_seq.pkl', 'rb') as f:\n    train_seq = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:37.448893Z","iopub.execute_input":"2023-04-12T06:41:37.449277Z","iopub.status.idle":"2023-04-12T06:41:44.812259Z","shell.execute_reply.started":"2023-04-12T06:41:37.449238Z","shell.execute_reply":"2023-04-12T06:41:44.811257Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of Training Sequence is {len(train_seq)} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:44.813687Z","iopub.execute_input":"2023-04-12T06:41:44.814147Z","iopub.status.idle":"2023-04-12T06:41:44.821847Z","shell.execute_reply.started":"2023-04-12T06:41:44.814109Z","shell.execute_reply":"2023-04-12T06:41:44.820737Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Number of Training Sequence is 2837544 \n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/working/lastfm/test_seq.pkl', 'rb') as f:\n    test_seq = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:44.823327Z","iopub.execute_input":"2023-04-12T06:41:44.824328Z","iopub.status.idle":"2023-04-12T06:41:47.956927Z","shell.execute_reply.started":"2023-04-12T06:41:44.824291Z","shell.execute_reply":"2023-04-12T06:41:47.955878Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of Test Sequence is {len(test_seq)} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:47.958359Z","iopub.execute_input":"2023-04-12T06:41:47.959028Z","iopub.status.idle":"2023-04-12T06:41:47.966199Z","shell.execute_reply.started":"2023-04-12T06:41:47.958989Z","shell.execute_reply":"2023-04-12T06:41:47.965217Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Number of Test Sequence is 672394 \n","output_type":"stream"}]},{"cell_type":"code","source":"SZ = 12\nSEQ_LEN = 10 ## Window Size to create a training Sequence\nBATCH_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:47.967607Z","iopub.execute_input":"2023-04-12T06:41:47.968648Z","iopub.status.idle":"2023-04-12T06:41:47.974099Z","shell.execute_reply.started":"2023-04-12T06:41:47.968613Z","shell.execute_reply":"2023-04-12T06:41:47.973061Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class SessionDataset(Dataset):\n    def __init__(self, data, max_len):\n\n        super(SessionDataset, self).__init__()\n        self.data=data\n        self.max_seq_len=max_len\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n\n        \n        data=self.data[index]\n        uid=np.array([data[0]],dtype=int)\n        browsed_ids=np.zeros((self.max_seq_len),dtype=int)\n        \n        seq_len=len(data[1][-self.max_seq_len:])\n        mask=np.array([1 for i in range(seq_len)]+[ 0 for i in range(self.max_seq_len-seq_len)],dtype=int)\n        pos_idx=np.array([seq_len-i-1 for i in range(seq_len)]+[ 0 for i in range(self.max_seq_len-seq_len)],dtype=int)\n        browsed_ids[:seq_len]=np.array(data[1][-self.max_seq_len:])\n        \n        seq_len=np.array(seq_len,dtype=int)\n   \n        label=np.array(data[2],dtype=int)\n\n        return uid,browsed_ids,mask,seq_len,label,pos_idx","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:47.975668Z","iopub.execute_input":"2023-04-12T06:41:47.976706Z","iopub.status.idle":"2023-04-12T06:41:47.987264Z","shell.execute_reply.started":"2023-04-12T06:41:47.976669Z","shell.execute_reply":"2023-04-12T06:41:47.986651Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_dataset = SessionDataset(train_seq, max_len=SEQ_LEN)\ntest_dataset = SessionDataset(test_seq, max_len=SEQ_LEN)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:47.994628Z","iopub.execute_input":"2023-04-12T06:41:47.995210Z","iopub.status.idle":"2023-04-12T06:41:48.001083Z","shell.execute_reply.started":"2023-04-12T06:41:47.995183Z","shell.execute_reply":"2023-04-12T06:41:48.000168Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(f\" Length of Training Dataset is {len(train_dataset)} & Test Dataset {len(test_dataset)} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.002713Z","iopub.execute_input":"2023-04-12T06:41:48.003103Z","iopub.status.idle":"2023-04-12T06:41:48.013398Z","shell.execute_reply.started":"2023-04-12T06:41:48.003043Z","shell.execute_reply":"2023-04-12T06:41:48.012337Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":" Length of Training Dataset is 2837544 & Test Dataset 672394 \n","output_type":"stream"}]},{"cell_type":"code","source":"train_iter = DataLoader(dataset=train_dataset,\n                            batch_size=BATCH_SIZE,\n                            num_workers=0,\n                            drop_last=False,\n                            shuffle=True,\n                            pin_memory=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.015105Z","iopub.execute_input":"2023-04-12T06:41:48.015946Z","iopub.status.idle":"2023-04-12T06:41:48.021908Z","shell.execute_reply.started":"2023-04-12T06:41:48.015910Z","shell.execute_reply":"2023-04-12T06:41:48.021008Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"test_iter = DataLoader(dataset=test_dataset,\n                            batch_size=BATCH_SIZE,\n                            num_workers=0,\n                            drop_last=False,\n                            shuffle=False,\n                            pin_memory=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.025040Z","iopub.execute_input":"2023-04-12T06:41:48.025318Z","iopub.status.idle":"2023-04-12T06:41:48.032563Z","shell.execute_reply.started":"2023-04-12T06:41:48.025288Z","shell.execute_reply":"2023-04-12T06:41:48.031604Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(f\" Length of Training DataLoader is {len(train_iter)} & Test DataLoader {len(test_iter)} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.034249Z","iopub.execute_input":"2023-04-12T06:41:48.034990Z","iopub.status.idle":"2023-04-12T06:41:48.041455Z","shell.execute_reply.started":"2023-04-12T06:41:48.034955Z","shell.execute_reply":"2023-04-12T06:41:48.040415Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":" Length of Training DataLoader is 5543 & Test DataLoader 1314 \n","output_type":"stream"}]},{"cell_type":"code","source":"eg = next(iter(train_iter))","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.042865Z","iopub.execute_input":"2023-04-12T06:41:48.043859Z","iopub.status.idle":"2023-04-12T06:41:48.352664Z","shell.execute_reply.started":"2023-04-12T06:41:48.043669Z","shell.execute_reply":"2023-04-12T06:41:48.351539Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of elements in the example tuple {len(eg)} - corresponds to uid | browsed_ids | mask | seq_len | label | pos_idx \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.354339Z","iopub.execute_input":"2023-04-12T06:41:48.354784Z","iopub.status.idle":"2023-04-12T06:41:48.360800Z","shell.execute_reply.started":"2023-04-12T06:41:48.354740Z","shell.execute_reply":"2023-04-12T06:41:48.359820Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Number of elements in the example tuple 6 - corresponds to uid | browsed_ids | mask | seq_len | label | pos_idx \n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Size of - \")\nprint(f\" User ID Tensor - {eg[0].size()} \") \nprint(f\" Sequence of Items - {eg[1].size()} \") \nprint(f\" Sequence of Masks - {eg[2].size()} \") \nprint(f\" Actual Sequence Length (before padding) - {eg[3].size()} \") \nprint(f\" Labels - {eg[4].size()} \") \nprint(f\" Position Index (Oldest Index = 0, Latest Index can be till 9, Padded Index = 0) - {eg[5].size()} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.362417Z","iopub.execute_input":"2023-04-12T06:41:48.363233Z","iopub.status.idle":"2023-04-12T06:41:48.373672Z","shell.execute_reply.started":"2023-04-12T06:41:48.363194Z","shell.execute_reply":"2023-04-12T06:41:48.372557Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Size of - \n User ID Tensor - torch.Size([512, 1]) \n Sequence of Items - torch.Size([512, 10]) \n Sequence of Masks - torch.Size([512, 10]) \n Actual Sequence Length (before padding) - torch.Size([512]) \n Labels - torch.Size([512, 1]) \n Position Index (Oldest Index = 0, Latest Index can be till 9, Padded Index = 0) - torch.Size([512, 10]) \n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Actual tensor of - \")\nprint(f\" User ID - {eg[0][0]} \") \nprint(f\" Sequence of Items - {eg[0][1]} \") \nprint(f\" Sequence of Masks - {eg[0][2]} \") \nprint(f\" Actual Sequence Length (before padding) - {eg[0][3]} \") \nprint(f\" Labels - {eg[0][4]} \") \nprint(f\" Position Index (Oldest Index = 0, Latest Index can be till 9, Padded Index = 0) - {eg[0][5]} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.375382Z","iopub.execute_input":"2023-04-12T06:41:48.375821Z","iopub.status.idle":"2023-04-12T06:41:48.385185Z","shell.execute_reply.started":"2023-04-12T06:41:48.375784Z","shell.execute_reply":"2023-04-12T06:41:48.383725Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Actual tensor of - \n User ID - tensor([723]) \n Sequence of Items - tensor([786]) \n Sequence of Masks - tensor([449]) \n Actual Sequence Length (before padding) - tensor([52]) \n Labels - tensor([108]) \n Position Index (Oldest Index = 0, Latest Index can be till 9, Padded Index = 0) - tensor([129]) \n","output_type":"stream"}]},{"cell_type":"code","source":"def sample_relations(num, sample_size=20):\n   \n    adj1 = [dict() for _ in range(num)]\n    adj2 = [dict() for _ in range(num)]\n    adj_in = [[] for _ in range(num)]\n    adj_out = [[] for _ in range(num)]\n    relation_out = []\n    relation_in = []\n\n    with open(os.path.join(saved_path, 'train.pkl'), 'rb') as f:\n        graph = pickle.load(f)\n\n    for u in tqdm(graph, desc='build the graph...', leave=False):\n        u_seqs = graph[u]\n        for s in u_seqs:\n            for i in range(len(s) - 1):\n                relation_out.append([s[i], s[i + 1]])\n                relation_in.append([s[i + 1], s[i]])\n  \n    for tup in relation_out:\n        if tup[1] in adj1[tup[0]].keys():\n            adj1[tup[0]][tup[1]] += 1\n        else:\n            adj1[tup[0]][tup[1]] = 1\n    for tup in relation_in:\n        if tup[1] in adj2[tup[0]].keys():\n            adj2[tup[0]][tup[1]] += 1\n        else:\n            adj2[tup[0]][tup[1]] = 1\n\n    weight = [[] for _ in range(num)]\n\n    for t in range(1, num):\n        x = [v for v in sorted(adj1[t].items(), reverse=True, key=lambda x: x[1])]\n        adj_out[t] = [v[0] for v in x]\n\n    for t in range(1, num):\n        x = [v for v in sorted(adj2[t].items(), reverse=True, key=lambda x: x[1])]\n        adj_in[t] = [v[0] for v in x]\n\n    for i in range(1, num):\n        adj_in[i] = adj_in[i][:sample_size]\n    for i in range(1, num):\n        adj_out[i] = adj_out[i][:sample_size]\n\n    with open(os.path.join(saved_path, f'adj_{sample_size}.pkl'), 'wb') as f:\n        pickle.dump([adj_in, adj_out], f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.387242Z","iopub.execute_input":"2023-04-12T06:41:48.387994Z","iopub.status.idle":"2023-04-12T06:41:48.404547Z","shell.execute_reply.started":"2023-04-12T06:41:48.387965Z","shell.execute_reply":"2023-04-12T06:41:48.403155Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sample_relations(num = 40000, sample_size=SZ)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:48.406316Z","iopub.execute_input":"2023-04-12T06:41:48.406891Z","iopub.status.idle":"2023-04-12T06:41:59.517096Z","shell.execute_reply.started":"2023-04-12T06:41:48.406850Z","shell.execute_reply":"2023-04-12T06:41:59.515908Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"build the graph...:   0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"with open(os.path.join(saved_path, f'adj_{SZ}.pkl'), 'rb') as f:\n    adj = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:59.518750Z","iopub.execute_input":"2023-04-12T06:41:59.519502Z","iopub.status.idle":"2023-04-12T06:41:59.592348Z","shell.execute_reply.started":"2023-04-12T06:41:59.519442Z","shell.execute_reply":"2023-04-12T06:41:59.591252Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"adj_in, adj_out = adj[0], adj[1]","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:59.593818Z","iopub.execute_input":"2023-04-12T06:41:59.594613Z","iopub.status.idle":"2023-04-12T06:41:59.600068Z","shell.execute_reply.started":"2023-04-12T06:41:59.594572Z","shell.execute_reply":"2023-04-12T06:41:59.598818Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(f\"Items which most frequently lies to the left (previous time step) of Item 1 : {adj_in[1]} \")\nprint(f\"Items which most frequently lies to the right (next time step) of Item 1 : {adj_out[1]} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:59.601768Z","iopub.execute_input":"2023-04-12T06:41:59.602502Z","iopub.status.idle":"2023-04-12T06:41:59.612985Z","shell.execute_reply.started":"2023-04-12T06:41:59.602443Z","shell.execute_reply":"2023-04-12T06:41:59.611663Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Items which most frequently lies to the left (previous time step) of Item 1 : [37151, 33669, 18558, 29129, 35336, 28294, 29082, 28263, 4905, 889, 34325, 22650] \nItems which most frequently lies to the right (next time step) of Item 1 : [34325, 33669, 6335, 17335, 36077, 29082, 36806, 889, 13645, 37151, 4304, 36082] \n","output_type":"stream"}]},{"cell_type":"code","source":"def userCF():\n    \"\"\"\n    calculate user similarity\n    \"\"\"\n    vid_user = {}\n    user_sim_matrix = {}\n    uid_vcount = {}\n    with open(os.path.join(saved_path,'train.pkl'), 'rb') as f:\n        session_data = pickle.load(f)\n    for uid in tqdm(session_data):\n        u_sess = session_data[uid]\n        uid_vcount.setdefault(uid, set())\n        for sess in u_sess:\n            for vid in sess:\n                if vid not in vid_user:\n                    vid_user[vid] = set()\n                vid_user[vid].add(uid)\n                if vid not in vid_user:\n                    vid_user[vid] = set()\n                vid_user[vid].add(uid)\n                uid_vcount[uid].add(vid)\n\n    for vid, users in tqdm(vid_user.items()):\n        for u in users:\n            for v in users:\n                if u == v:\n                    continue\n                user_sim_matrix.setdefault(u, {})\n                user_sim_matrix[u].setdefault(v, 0)\n                user_sim_matrix[u][v] += (1 / len(users))\n    for u, related_users in user_sim_matrix.items():\n        for v, count in related_users.items():\n            user_sim_matrix[u][v] = count / math.sqrt(len(uid_vcount[u]) * len(uid_vcount[v]))\n    user_topK = {}\n    for user in user_sim_matrix:\n        user_topK[user] = sorted(user_sim_matrix[user].items(), key=itemgetter(1), reverse=True)[0:100]\n    with open(os.path.join(saved_path,'u2u_sim.pkl'), 'wb') as f:\n        pickle.dump(user_topK, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:59.614651Z","iopub.execute_input":"2023-04-12T06:41:59.615023Z","iopub.status.idle":"2023-04-12T06:41:59.628395Z","shell.execute_reply.started":"2023-04-12T06:41:59.614988Z","shell.execute_reply":"2023-04-12T06:41:59.627197Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def itemCFSession():\n\n    sess_item = {}\n    item_sim_matrix = {}\n    vid_ucount = {}\n    sess_cnt = 0\n    \n    with open(os.path.join(saved_path,'train.pkl'), 'rb') as f:\n        session_data = pickle.load(f)\n        \n    for uid in tqdm(session_data):\n        u_sess = session_data[uid]\n       \n        for sess in u_sess:\n            sess_cnt += 1\n            sess_item[sess_cnt] = set()\n            for vid in sess:\n                sess_item[sess_cnt].add(vid)\n                vid_ucount.setdefault(vid, set())\n                vid_ucount[vid].add(sess_cnt)\n\n    for sess, items in tqdm(sess_item.items()):\n        for v in items:\n            for _v in items:\n                if _v == v:\n                    continue\n                item_sim_matrix.setdefault(v, {})\n                item_sim_matrix[v].setdefault(_v, 0)\n                item_sim_matrix[v][_v] += (1 / len(items))\n                \n    for v, related_items in item_sim_matrix.items():\n        for _v, count in related_items.items():\n            item_sim_matrix[v][_v] = count / math.sqrt(len(vid_ucount[v]) * len(vid_ucount[_v]))\n    item_topK = {}\n    \n    for item in item_sim_matrix:\n        item_topK[item] = sorted(item_sim_matrix[item].items(), key=itemgetter(1), reverse=True)[0:200]\n    with open(os.path.join(saved_path,'i2i_sim_sess.pkl'), 'wb') as f:\n        pickle.dump(item_topK, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:59.629882Z","iopub.execute_input":"2023-04-12T06:41:59.630659Z","iopub.status.idle":"2023-04-12T06:41:59.643759Z","shell.execute_reply.started":"2023-04-12T06:41:59.630621Z","shell.execute_reply":"2023-04-12T06:41:59.642749Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"userCF()","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:41:59.646175Z","iopub.execute_input":"2023-04-12T06:41:59.646518Z","iopub.status.idle":"2023-04-12T06:42:26.631099Z","shell.execute_reply.started":"2023-04-12T06:41:59.646469Z","shell.execute_reply":"2023-04-12T06:42:26.630062Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0c26776427640a3950c7d31d1f65e65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/38569 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61aeab41be0045af84d5a6c0494605ec"}},"metadata":{}}]},{"cell_type":"code","source":"itemCFSession()","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:42:26.635983Z","iopub.execute_input":"2023-04-12T06:42:26.638197Z","iopub.status.idle":"2023-04-12T06:43:12.928996Z","shell.execute_reply.started":"2023-04-12T06:42:26.638158Z","shell.execute_reply":"2023-04-12T06:43:12.927874Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be59c2dbb2ea426a81eb5d65a89f3841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/260766 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de0a6c9c3dfa4613bd42aad4365f0851"}},"metadata":{}}]},{"cell_type":"code","source":"with open(os.path.join(saved_path,'u2u_sim.pkl'), 'rb') as f:\n    u2u_sim = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:12.932441Z","iopub.execute_input":"2023-04-12T06:43:12.932838Z","iopub.status.idle":"2023-04-12T06:43:12.960101Z","shell.execute_reply.started":"2023-04-12T06:43:12.932807Z","shell.execute_reply":"2023-04-12T06:43:12.959216Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(f\"#Users in the User Sim. Matrix {len(u2u_sim.keys())}, each having Top {len(u2u_sim[1])} Similar User \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:12.961407Z","iopub.execute_input":"2023-04-12T06:43:12.961973Z","iopub.status.idle":"2023-04-12T06:43:12.967772Z","shell.execute_reply.started":"2023-04-12T06:43:12.961936Z","shell.execute_reply":"2023-04-12T06:43:12.966777Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"#Users in the User Sim. Matrix 897, each having Top 100 Similar User \n","output_type":"stream"}]},{"cell_type":"code","source":"with open(os.path.join(saved_path,'i2i_sim_sess.pkl'), 'rb') as f:\n    i2i_sim = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:12.969266Z","iopub.execute_input":"2023-04-12T06:43:12.969902Z","iopub.status.idle":"2023-04-12T06:43:14.067522Z","shell.execute_reply.started":"2023-04-12T06:43:12.969865Z","shell.execute_reply":"2023-04-12T06:43:14.066530Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"print(f\"#Items in the Item Sim. Matrix {len(i2i_sim.keys())} and Item1 has similar {len(i2i_sim[1])} Items while Item2 has similar {len(i2i_sim[2])} Items \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:14.068961Z","iopub.execute_input":"2023-04-12T06:43:14.069652Z","iopub.status.idle":"2023-04-12T06:43:14.076061Z","shell.execute_reply.started":"2023-04-12T06:43:14.069604Z","shell.execute_reply":"2023-04-12T06:43:14.074879Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"#Items in the Item Sim. Matrix 38569 and Item1 has similar 75 Items while Item2 has similar 39 Items \n","output_type":"stream"}]},{"cell_type":"code","source":"def uui_graph(sample_size, topK, add_u = True, add_v = True):\n    \n    \n    pre = []\n    nxt = []\n    src_v = []\n    dst_u = []\n\n    with open(os.path.join(saved_path,'train.pkl'), 'rb') as f:\n        graph = pickle.load(f)\n\n    with open(os.path.join(saved_path,f'adj_{sample_size}.pkl'), 'rb') as f:\n        adj = pickle.load(f)\n        \n    adj_in = adj[0]\n    adj_out = adj[1]\n    \n    print('adj_in:', len(adj_in))\n    print('adj_out:', len(adj_out))\n    \n    for i in range(len(adj_in)):\n        if i == 0:\n            continue\n        _pre = []\n        _nxt = []\n        for item in adj_in[i]:\n            _pre.append(i)\n            _nxt.append(item)\n        pre += _pre\n        nxt += _nxt\n    o_pre = []\n    o_nxt = []\n    for i in range(len(adj_out)):\n        if i == 0:\n            continue\n        _pre = []\n        _nxt = []\n        for item in adj_out[i]:\n            _pre.append(i)\n            _nxt.append(item)\n        o_pre += _pre\n        o_nxt += _nxt\n        \n    for u in tqdm(graph, desc='build the graph...', leave=False):\n        u_seqs = graph[u]\n        for s in u_seqs:\n            pre += s[:-1]\n            nxt += s[1:]\n            dst_u += [u for _ in s]\n            src_v += s\n\n    with open(os.path.join(saved_path,'u2u_sim.pkl'), 'rb') as f:\n        u2u_sim = pickle.load(f)\n\n    with open(os.path.join(saved_path,'i2i_sim_sess.pkl'),'rb') as f:\n        i2i_sim=pickle.load(f)\n\n    topv_src=[]\n    topv_dst=[]\n    count_v=0\n    for v in tqdm(i2i_sim,desc='gen_seq...',leave=False):\n        tmp_src=[]\n        tmp_dst=[]\n\n        exclusion=adj_in[v]+adj_out[v]\n        for (vid,value) in i2i_sim[v][:topK][:int(len(exclusion))]:\n            if vid not in exclusion:\n                tmp_src.append(vid)\n                tmp_dst.append(v)\n        topv_src+=tmp_src\n        topv_dst+=tmp_dst\n\n    u_src = []\n    u_dst = []\n    for u in tqdm(u2u_sim, desc='gen_seq...', leave=False):\n        tmp_src = []\n        tmp_dst = []\n        for (uid, value) in u2u_sim[u][:topK]:\n            tmp_src.append(uid)\n            tmp_dst.append(u)\n        u_src += tmp_src\n        u_dst += tmp_dst\n\n    count = 0\n    for i in adj_in:\n        count += len(i)\n    print('local ajdency-in:', count / len(adj_in))\n    count = 0\n    for i in adj_out:\n        count += len(i)\n    print('local ajdency-out:', count / len(adj_out))\n\n    item_num = max(max(pre), max(nxt)) +1\n    print('addiotn item num', item_num)\n    user_num = max(max(u_src), max(u_dst))\n    u_src = [u + item_num for u in u_src]\n    u_dst = [u + item_num for u in u_dst]\n    dst_u = [u + item_num for u in dst_u]\n\n    G = dgl.graph((pre, nxt))\n    G = dgl.add_edges(G, nxt, pre)\n    G = dgl.add_edges(G, dst_u, src_v)\n    G = dgl.add_edges(G, src_v, dst_u)\n\n    if add_u:\n        G = dgl.add_edges(G, u_src, u_dst)\n        G = dgl.add_edges(G, u_dst, u_src)\n    \n    if add_v:\n        G = dgl.add_edges(G, topv_src, topv_dst)\n        G = dgl.add_edges(G, topv_dst, topv_src)\n\n\n    G=dgl.add_self_loop(G)\n\n    return G,item_num, pre, nxt, dst_u, src_v, u_src, u_dst, topv_src, topv_dst","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:14.077608Z","iopub.execute_input":"2023-04-12T06:43:14.078166Z","iopub.status.idle":"2023-04-12T06:43:14.099382Z","shell.execute_reply.started":"2023-04-12T06:43:14.078131Z","shell.execute_reply":"2023-04-12T06:43:14.098342Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"G,item_num, pre, nxt, dst_u, src_v, u_src, u_dst, topv_src, topv_dst = uui_graph(SZ, topK = 20, add_u = True, add_v = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:14.101428Z","iopub.execute_input":"2023-04-12T06:43:14.101861Z","iopub.status.idle":"2023-04-12T06:43:19.988209Z","shell.execute_reply.started":"2023-04-12T06:43:14.101815Z","shell.execute_reply":"2023-04-12T06:43:19.987177Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"adj_in: 40000\nadj_out: 40000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"build the graph...:   0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"gen_seq...:   0%|          | 0/38569 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"gen_seq...:   0%|          | 0/897 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"local ajdency-in: 8.254125\nlocal ajdency-out: 8.256525\naddiotn item num 38570\n","output_type":"stream"}]},{"cell_type":"code","source":"num_edges_typeA = len(pre)\nnum_edges_typeB = len(topv_src)\nnum_edges_typeC = len(u_src)\nnum_edges_typeD = len(src_v)\nprint(f\"Number Type A Edges : {num_edges_typeA}\")\nprint(f\"Number Type B Edges : {num_edges_typeB}\")\nprint(f\"Number Type C Edges : {num_edges_typeC}\")\nprint(f\"Number Type D Edges : {num_edges_typeD}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:19.989606Z","iopub.execute_input":"2023-04-12T06:43:19.990106Z","iopub.status.idle":"2023-04-12T06:43:19.997689Z","shell.execute_reply.started":"2023-04-12T06:43:19.990068Z","shell.execute_reply":"2023-04-12T06:43:19.996551Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Number Type A Edges : 3167709\nNumber Type B Edges : 426471\nNumber Type C Edges : 17940\nNumber Type D Edges : 3098310\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Total Number of Edges : { G.num_nodes() + 2*num_edges_typeA + 2*num_edges_typeB + 2*num_edges_typeC + 2*num_edges_typeD} \" )","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:19.999150Z","iopub.execute_input":"2023-04-12T06:43:19.999614Z","iopub.status.idle":"2023-04-12T06:43:20.008344Z","shell.execute_reply.started":"2023-04-12T06:43:19.999573Z","shell.execute_reply":"2023-04-12T06:43:20.007226Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Total Number of Edges : 13460423 \n","output_type":"stream"}]},{"cell_type":"code","source":"G","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:20.010050Z","iopub.execute_input":"2023-04-12T06:43:20.011165Z","iopub.status.idle":"2023-04-12T06:43:20.018899Z","shell.execute_reply.started":"2023-04-12T06:43:20.011128Z","shell.execute_reply":"2023-04-12T06:43:20.017740Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"Graph(num_nodes=39563, num_edges=13460423,\n      ndata_schemes={}\n      edata_schemes={})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport dgl.nn.pytorch as dglnn\nimport dgl.function as FN\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:20.020708Z","iopub.execute_input":"2023-04-12T06:43:20.021314Z","iopub.status.idle":"2023-04-12T06:43:20.027585Z","shell.execute_reply.started":"2023-04-12T06:43:20.021279Z","shell.execute_reply":"2023-04-12T06:43:20.026477Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class HG_GNN(nn.Module):\n    # @torchsnooper.snoop()\n    def __init__(self, G, config,item_num, max_seq_len=10, max_sess = 10):\n        super().__init__()\n        self.G = G.to(device)\n        self.max_sess = max_sess\n        self.hidden_size = config['hidden_size']\n        self.em_size = config['embed_size']\n        self.pos_embedding = nn.Embedding(200, self.em_size)\n        self.v2e = nn.Embedding(G.number_of_nodes(), self.em_size).to(device)\n\n        self.conv1 = dglnn.SAGEConv(self.em_size, self.em_size, 'mean')\n\n        dropout = config[\"dropout\"]\n        self.emb_dropout = nn.Dropout(p=dropout)\n        self.gru = nn.GRU(self.em_size, self.hidden_size, 1)\n        self.max_seq_len = max_seq_len\n        self.W = nn.Linear(self.em_size, self.em_size)\n\n\n        self.linear_one = nn.Linear(self.em_size, self.em_size, bias=True)\n        self.linear_two = nn.Linear(self.em_size, self.em_size, bias=True)\n        self.linear_three = nn.Linear(self.em_size, 1, bias=False)\n\n\n        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size)\n        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size)\n        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n\n        self.ct_dropout = nn.Dropout(dropout)\n        \n        self.user_transform = nn.Sequential(\n            # nn.ReLU(),\n            nn.Linear(self.em_size, self.em_size, bias=True)\n            # nn.BatchNorm1d(predict_em_size, momentum=0.5),\n        )\n\n        self.gru_transform = nn.Sequential(\n            # nn.ReLU(),\n            nn.Linear(self.hidden_size * 2, self.em_size, bias=True)\n            # nn.BatchNorm1d(predict_em_size, momentum=0.5),\n        )\n\n        self.sigmoid_concat = nn.Sequential(\n            nn.Linear(self.em_size * 2, 1, bias=True),\n            nn.Sigmoid()\n            # nn.BatchNorm1d(predict_em_size, momentum=0.5),\n        )\n\n        self.w_1 = nn.Parameter(torch.Tensor(2 * self.em_size, self.em_size))\n        self.w_2 = nn.Parameter(torch.Tensor(self.em_size, 1))\n        self.glu1 = nn.Linear(self.em_size, self.em_size)\n        self.glu2 = nn.Linear(self.em_size, self.em_size, bias=False)\n\n        self.w_3 = nn.Parameter(torch.Tensor(self.em_size, self.em_size))\n        self.w_4 = nn.Parameter(torch.Tensor(self.em_size, 1))\n        self.glu3 = nn.Linear(self.em_size, self.em_size)\n        self.glu4 = nn.Linear(self.em_size, self.em_size, bias=False)\n\n        self.reset_parameters()\n\n        self.item_num = item_num\n\n\n    def reset_parameters(self):\n        stdv = 1.0 / math.sqrt(self.em_size)\n        for weight in self.parameters():\n            weight.data.uniform_(-stdv, stdv)\n\n\n    def compute_hidden_vector(self, hidden, mask, pos_idx):\n\n        mask = mask.float().unsqueeze(-1)\n        batch_size = hidden.shape[0]\n        len = hidden.shape[1]\n        pos_emb = self.pos_embedding(pos_idx)\n        tmp = torch.sum(hidden * mask, -2) / torch.sum(mask, 1)\n        hs = tmp.unsqueeze(-2).repeat(1, len, 1)\n        nh = torch.matmul(torch.cat([pos_emb, hidden], -1), self.w_1)\n        nh = torch.tanh(nh)\n        nh = torch.sigmoid(self.glu1(nh) + self.glu2(hs))\n        beta = torch.matmul(nh, self.w_2)\n        beta = beta * mask\n        select = torch.sum(beta * hidden, 1)\n\n        return select, tmp\n\n\n    def sess_user_vector(self, user_vec, note_embeds,mask):\n\n        mask = mask.float().unsqueeze(-1)\n        hs = user_vec.repeat(1, mask.shape[1], 1)\n        nh = torch.matmul(note_embeds, self.w_3)\n        nh = torch.tanh(nh)\n        nh = torch.sigmoid(self.glu3(nh) + self.glu4(hs))\n        beta = torch.matmul(nh, self.w_4)\n        beta = beta * mask\n        select = torch.sum(beta * note_embeds, 1)\n\n        return select\n\n\n    def forward(self, user, seq, mask, seq_len, pos_idx):\n\n        user = user + self.item_num\n\n\n        h1 = self.conv1( self.G, self.emb_dropout(self.v2e(torch.arange(0, self.G.number_of_nodes()).long().to(device) ) ) )\n        h1 = F.relu(h1)\n\n        bs = seq.size()[0]\n        L = seq.size()[1]\n\n        node_list = seq\n        item_embeds = ( h1[node_list] + self.v2e(node_list)) / 2\n        user_embeds = ( h1[user] + self.v2e(user)) / 2\n        node_embeds = item_embeds.view((bs, L, -1))\n        seq_embeds = user_embeds\n\n        sess_vec, avg_sess = self.compute_hidden_vector(node_embeds, mask, pos_idx)\n        sess_user = self.sess_user_vector(user_embeds, node_embeds, mask)\n        alpha = self.sigmoid_concat(torch.cat([sess_vec, sess_user], 1))\n        seq_embeds =  (alpha * sess_vec + (1 - alpha) * sess_user)\n        item_embs = self.v2e.weight[1:]  \n        scores = torch.matmul(seq_embeds, item_embs.permute(1, 0))\n\n        return scores\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:20.029719Z","iopub.execute_input":"2023-04-12T06:43:20.030603Z","iopub.status.idle":"2023-04-12T06:43:20.329656Z","shell.execute_reply.started":"2023-04-12T06:43:20.030392Z","shell.execute_reply":"2023-04-12T06:43:20.328547Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"config = {\n'embed_size' : 128,\n'learning_rate' : 0.001,\n'hidden_size' : 64,\n'batch_size' : 512,\n'epoch' : 3,\n'gnn_layer_size' : 2,\n'patience' : 5,\n'save_flag' : 0,\n'dropout' : 0.5, \n'comment' : \"\",\n'lr_dc_step' : 3,\n'lr_dc' : 0.1\n}","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:20.333680Z","iopub.execute_input":"2023-04-12T06:43:20.334011Z","iopub.status.idle":"2023-04-12T06:43:20.342365Z","shell.execute_reply.started":"2023-04-12T06:43:20.333974Z","shell.execute_reply":"2023-04-12T06:43:20.341370Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:20.343794Z","iopub.execute_input":"2023-04-12T06:43:20.344224Z","iopub.status.idle":"2023-04-12T06:43:20.353882Z","shell.execute_reply.started":"2023-04-12T06:43:20.344188Z","shell.execute_reply":"2023-04-12T06:43:20.352785Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"G.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:20.355654Z","iopub.execute_input":"2023-04-12T06:43:20.356062Z","iopub.status.idle":"2023-04-12T06:43:21.188591Z","shell.execute_reply.started":"2023-04-12T06:43:20.356027Z","shell.execute_reply":"2023-04-12T06:43:21.187511Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"Graph(num_nodes=39563, num_edges=13460423,\n      ndata_schemes={}\n      edata_schemes={})"},"metadata":{}}]},{"cell_type":"code","source":"model = HG_GNN(G, config, item_num, SEQ_LEN).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:21.189905Z","iopub.execute_input":"2023-04-12T06:43:21.190366Z","iopub.status.idle":"2023-04-12T06:43:21.926160Z","shell.execute_reply.started":"2023-04-12T06:43:21.190327Z","shell.execute_reply":"2023-04-12T06:43:21.925120Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"eg = next(iter(train_iter))","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:21.928467Z","iopub.execute_input":"2023-04-12T06:43:21.929332Z","iopub.status.idle":"2023-04-12T06:43:22.177082Z","shell.execute_reply.started":"2023-04-12T06:43:21.929278Z","shell.execute_reply":"2023-04-12T06:43:22.176037Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"eg[0].size(), eg[1].size(), eg[2].size(), eg[3].size(), eg[4].size(), eg[5].size(),","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:22.178410Z","iopub.execute_input":"2023-04-12T06:43:22.179311Z","iopub.status.idle":"2023-04-12T06:43:22.187742Z","shell.execute_reply.started":"2023-04-12T06:43:22.179272Z","shell.execute_reply":"2023-04-12T06:43:22.186731Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(torch.Size([512, 1]),\n torch.Size([512, 10]),\n torch.Size([512, 10]),\n torch.Size([512]),\n torch.Size([512, 1]),\n torch.Size([512, 10]))"},"metadata":{}}]},{"cell_type":"code","source":"uid, browsed_ids, mask, seq_len, label, pos_idx = eg[0], eg[1], eg[2], eg[3], eg[4], eg[5]","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:22.189266Z","iopub.execute_input":"2023-04-12T06:43:22.189827Z","iopub.status.idle":"2023-04-12T06:43:22.196357Z","shell.execute_reply.started":"2023-04-12T06:43:22.189793Z","shell.execute_reply":"2023-04-12T06:43:22.195294Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"outputs = model(uid.to(device), \n                browsed_ids.to(device),\n                mask.to(device),\n                seq_len.to(device),\n                pos_idx.to(device)\n                )","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:22.198032Z","iopub.execute_input":"2023-04-12T06:43:22.198540Z","iopub.status.idle":"2023-04-12T06:43:23.621588Z","shell.execute_reply.started":"2023-04-12T06:43:22.198476Z","shell.execute_reply":"2023-04-12T06:43:23.620611Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"print(f\"Size of Label is {label.size()} & Model Output {outputs.size()} \")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:23.622814Z","iopub.execute_input":"2023-04-12T06:43:23.623170Z","iopub.status.idle":"2023-04-12T06:43:23.628099Z","shell.execute_reply.started":"2023-04-12T06:43:23.623135Z","shell.execute_reply":"2023-04-12T06:43:23.627063Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Size of Label is torch.Size([512, 1]) & Model Output torch.Size([512, 39562]) \n","output_type":"stream"}]},{"cell_type":"code","source":"def train(config, model, device, train_iter, test_iter=None):\n    model.train()\n    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"lr_dc_step\"], gamma=config[\"lr_dc\"])\n    \n    dev_best_loss = float('inf')\n    last_improve = 0 \n    flag = False  \n    AUC_best = 0\n    loss_list = []\n    best_acc = 0\n    STEP_SIZE = 2000\n    batchs = train_iter.__len__()\n\n    for epoch in range(config['epoch']):\n        print('Epoch [{}/{}]'.format(epoch + 1, config['epoch']))\n        loss_records = []\n        L = nn.CrossEntropyLoss()\n        total_batch = 0 \n        for i, (uid, browsed_ids, mask, seq_len, label, pos_idx) in enumerate(train_iter):\n            model.train()\n            outputs = model(uid.to(device), \n                            browsed_ids.to(device),\n                            mask.to(device),\n                            seq_len.to(device),\n                            pos_idx.to(device)\n                            )\n            model.zero_grad()\n            loss = L(outputs, (label - 1).to(device).squeeze())\n            loss_list.append(loss.item())\n            loss_records.append(loss.item())\n            loss.backward()\n            optimizer.step()\n            \n            if total_batch == 0:\n                print(f'Initial training Loss is {round(np.mean(loss_records),2)}')\n\n            if (total_batch+1) % STEP_SIZE == 0:\n                print(f'Average training Loss till Batch {total_batch+1} is {round(np.mean(loss_records),2)}')\n                loss_list = []\n            total_batch += 1\n\n        print('preformance on test set....')\n        scheduler.step()\n        acc = evaluate_topk(config, model, test_iter)\n        \n        if acc > best_acc:\n            best_acc = acc\n            last_improve = 0\n            \n            torch.save({\n                'model' : model.state_dict(),\n                'optimizer' : optimizer.state_dict(),\n                'scheduler' : scheduler.state_dict(),\n                'Accuracy@20' : acc,\n                'epoch' : epoch\n            }, os.path.join(saved_path, f'{epoch}.pt'))\n            \n        else:\n            last_improve += 1\n            if last_improve >= config['patience']:\n                print('Early stop: No more improvement')\n                break\n\n\ndef metrics(res, labels):\n    res = np.concatenate(res)\n    acc_ar = (res == labels)  # [BS, K]\n    acc = acc_ar.sum(-1)\n\n    rank = np.argmax(acc_ar, -1) + 1\n    mrr = (acc / rank).mean()\n    ndcg = (acc / np.log2(rank + 1)).mean()\n    return acc.mean(), mrr, ndcg\n\n\ndef evaluate_topk(config, model, data_iter, K=20):\n    model.eval()\n    hit = []\n    res50 = []\n    res20 = []\n    res10 = []\n    res5 = []\n    mrr = []\n    labels = []\n    uids = []\n    with torch.no_grad():\n        with tqdm(total=(data_iter.__len__()), desc='Predicting', leave=False) as p:\n            for i, (uid, browsed_ids, mask, seq_len, label, pos_idx) in (enumerate(data_iter)):\n                outputs = model(uid.to(device), browsed_ids.to(device), mask.to(device), seq_len.to(device),\n                                pos_idx.to(device)\n                                )\n                sub_scores = outputs.topk(K)[1].cpu()\n                res20.append(sub_scores)\n                res10.append(outputs.topk(10)[1].cpu())\n                res5.append(outputs.topk(5)[1].cpu())\n                res50.append(outputs.topk(50)[1].cpu())\n                labels.append(label)\n                \n    labels = np.concatenate(labels)  # .flatten()\n    labels = labels - 1\n    \n    acc50, mrr50, ndcg50 = metrics(res50, labels)\n    acc20, mrr20, ndcg20 = metrics(res20, labels)\n    acc10, mrr10, ndcg10 = metrics(res10, labels)\n    acc5, mrr5, ndcg5 = metrics(res5, labels)\n\n    print(\"Top20 : acc {} , mrr {}, ndcg {}\".format(acc20, mrr20, ndcg20))\n    print(\"Top10 : acc {} , mrr {}, ndcg {}\".format(acc10, mrr10, ndcg10))\n    print(\"Top5 : acc {} , mrr {}, ndcg {}\".format(acc5, mrr5, ndcg5))\n\n    return acc20  ","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:23.629711Z","iopub.execute_input":"2023-04-12T06:43:23.630319Z","iopub.status.idle":"2023-04-12T06:43:23.653013Z","shell.execute_reply.started":"2023-04-12T06:43:23.630276Z","shell.execute_reply":"2023-04-12T06:43:23.652022Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"train(config, model, device, train_iter, test_iter)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T06:43:23.654613Z","iopub.execute_input":"2023-04-12T06:43:23.655013Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/3]\nInitial training Loss is 10.58\nAverage training Loss till Batch 2000 is 7.32\nAverage training Loss till Batch 4000 is 6.98\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}